{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Server.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3tAZ7PzFN-Bu",
        "eOitYKybQuc_",
        "nKIYfm7WROXc",
        "RMjF2ohvRyGL"
      ],
      "mount_file_id": "11v7WtxDFdbTfrxTbBKytvHd30KxAyoHi",
      "authorship_tag": "ABX9TyOMhRMlk6fgT5ge5871Q/Sb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krnvz/server_client/blob/main/server/Server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAKcR2slk1jo"
      },
      "source": [
        "# `CLAUDIO PINCHEIRA ROZAS`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E48yDH03VBo5"
      },
      "source": [
        "![FASTAI (1).png](https://i.ibb.co/YTDrfMk/SERVER-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tAZ7PzFN-Bu"
      },
      "source": [
        "### Inicializaciones "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr3agiNxVbVW"
      },
      "source": [
        "#@title Instalación de paquetes \n",
        "%%capture\n",
        "!pip install opencv-python tensorflow\n",
        "!pip install cvlib\n",
        "!pip install uvicorn\n",
        "!pip install fastapi\n",
        "!pip install python-multipart\n",
        "!pip install nest-asyncio\n",
        "!pip install Pillow\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "!pip install colabcode"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5CQfFcuTv5r"
      },
      "source": [
        "#@title librerias\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "import cv2\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "import io\n",
        "import uvicorn\n",
        "import numpy as np\n",
        "import nest_asyncio\n",
        "from enum import Enum\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from fastapi.responses import StreamingResponse"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZzf5KIPOGFb"
      },
      "source": [
        "### Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOitYKybQuc_"
      },
      "source": [
        "#### Directorios necesarios\n",
        "Creación de directorios para almacenar las imágenes subidas al servidor y aquellas procesadas (con las detecciones)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFiiTjQwUDHQ"
      },
      "source": [
        "# Creación de directorio para guardar las imagenes con detecciones\n",
        "# ==============================================================================\n",
        "location = '/content/'\n",
        "dir_name = \"images_with_boxes\"\n",
        "if not os.path.exists(location + dir_name):\n",
        "    os.mkdir(location + dir_name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRScFGoCWFEu"
      },
      "source": [
        "# crear un directorio para guardar las imágenes que se vayan subiendo al servidor:\n",
        "# ==============================================================================\n",
        "dir_name = \"images_uploaded\"\n",
        "location_imagen_uploaded = f\"/content/\" + dir_name\n",
        "if not os.path.exists(location_imagen_uploaded):\n",
        "    os.mkdir(location_imagen_uploaded)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKIYfm7WROXc"
      },
      "source": [
        "#### Procesos del servidor\n",
        "\n",
        "Asignación de una instancia de la clase FastAPI y definiciones de endpoints, con sus respectivos proceso tanto para identificar o  contar objetos en imágenes.\n",
        "\n",
        "Funcionamiento de los endpoints:\n",
        "* `/predict`: se le debe indicar un nivel de confianza, un modelo a utilizar y una imagen a evaluar. Retorna una imagen con la respectiva identificación y demarcación de un objeto y su etiqueta\n",
        "* `/countObjects`:  se le debe indicar el nombre de algún objeto (en ingles y de forma singular), un nivel de confianza, un modelo a utilizar y por último la imagen a evaluar. Retorna la cantidad de objetos de interés, en la imagen.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJbJtL9jV9bU"
      },
      "source": [
        "# Asignamos una instancia de la clase FastAPI a la variable \"app\".\n",
        "# ==============================================================================\n",
        "app = FastAPI(title='Implementando un modelo de Machine Learning usando FastAPI')\n",
        "\n",
        "# Enlistamos los modelos disponibles usando Enum. Útil cuando tenemos opciones predefinidas.\n",
        "class Model(str, Enum):\n",
        "    yolov3tiny = \"yolov3-tiny\"\n",
        "    yolov3 = \"yolov3\"\n",
        "\n",
        "\n",
        "# Usando @app.get(\"/\") definimos un método GET para el endpoint / (que sería como el \"home\")\n",
        "# ==============================================================================\n",
        "@app.get(\"/\")\n",
        "def home():\n",
        "    return \"¡Felicitaciones! Tu API está funcionando según lo esperado. Anda ahora a http://localhost:8000/docs.\"\n",
        "\n",
        "\n",
        "# Este endpoint maneja la lógica necesaria para detectar objetos.\n",
        "# Requiere como entrada el modelo deseado y la imagen.\n",
        "@app.post(\"/predict\") \n",
        "def prediction(confidence, model: Model, file: UploadFile = File(...)):\n",
        "\n",
        "    # 1. Validar el archivo de entrada\n",
        "    filename = file.filename\n",
        "    fileExtension = filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n",
        "    if not fileExtension:\n",
        "        raise HTTPException(status_code=415, detail=\"Tipo de archivo no soportado.\")\n",
        "    \n",
        "    # 2. Transformar la imagen cruda a una imagen CV2\n",
        "    \n",
        "    # Leer la imagen como un stream de bytes\n",
        "    image_stream = io.BytesIO(file.file.read())\n",
        "    \n",
        "    # Empezar el stream desde el principio (posicion cero)\n",
        "    image_stream.seek(0)\n",
        "    \n",
        "    # Escribir el stream en un numpy array\n",
        "    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)\n",
        "    \n",
        "    # Decodificar el numpy array como una imagen\n",
        "    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "    \n",
        "    \n",
        "    # 3. Correr el modelo de detección de objetos\n",
        "    \n",
        "    # Correr la detección de objetos\n",
        "    bbox, label, conf = cv.detect_common_objects(image, confidence= float(confidence) ,model=model)\n",
        "    \n",
        "    # Crear una imagen que contenga las cajas delimitadoras y etiquetas\n",
        "    output_image = draw_bbox(image, bbox, label, conf)\n",
        "    \n",
        "    # Guardarla en un directorio del server\n",
        "    cv2.imwrite(f'/content/images_uploaded/{filename}', output_image)\n",
        "    \n",
        "    \n",
        "    # 4. Transmitir la respuesta de vuelta al cliente\n",
        "    \n",
        "    # Abrir la imagen para leerla en formato binario\n",
        "    file_image = open(f'/content/images_uploaded/{filename}', mode=\"rb\")\n",
        "    \n",
        "    # Retornar la imagen como un stream usando un formato específico\n",
        "    return StreamingResponse(file_image, media_type=\"image/jpeg\")\n",
        "\n",
        "@app.post(\"/countObjects\") \n",
        "def contadorObjetos(Objects , confidence , model: Model,file: UploadFile = File(...)):\n",
        "    \"\"\"\n",
        "    Argumentos:\n",
        "        Objects: string de objetos en ingles y de forma singular\n",
        "        confidence: float, umbral de confianza para la asignación de la predicción\n",
        "        model: modelo a usar\n",
        "        file: (_io.BufferedReader) Archivo a subir, debe ser una imagen.\n",
        "    \"\"\"\n",
        "\n",
        "    # PASO 1. Validar el archivo de entrada\n",
        "    # ==============================================================================\n",
        "    filename = file.filename #nombre del archivo\n",
        "    fileExtension = filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\") #verificar tipo de archivo\n",
        "    if not fileExtension:\n",
        "        raise HTTPException(status_code=415, detail=\"Tipo de archivo no soportado.\")\n",
        "\n",
        "    # PASO 2. Transformar la imagen cruda a una imagen CV2\n",
        "    # ==============================================================================    \n",
        "    image_stream = io.BytesIO(file.file.read())    # Leer la imagen como un stream de bytes\n",
        "    image_stream.seek(0)   # Empezar el stream desde el principio (posicion cero)\n",
        "    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)   # Escribir el stream en un numpy array\n",
        "    \n",
        "    # Decodificar el numpy array como una imagen\n",
        "    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "    \n",
        "\n",
        "    # PASO 3. Correr el modelo de detección de objetos\n",
        "    # ==============================================================================   \n",
        "    # Correr la detección de objetos\n",
        "    bbox, label, conf = cv.detect_common_objects(image, confidence= float(confidence) ,model=model)\n",
        "    \n",
        "    # Contar los objetos iguales a la palabra 'Object'\n",
        "    count_obj = label.count(Objects)\n",
        "    respuesta = 'Con un nivel de confianza de {}, se predice que en la imagen {} aparece {} veces el objeto {}'.format(float(confidence), filename, count_obj, Objects)\n",
        "    return respuesta"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMjF2ohvRyGL"
      },
      "source": [
        "####  Iniciar el servidor de código `colabcode`\n",
        "La url aparecerá luego de correr la apps en el servidor y sera similar a: \n",
        "* `https://ad9aa39ca7d8.ngrok.io ====> ` (*enlace a modo de ejemplo, no usar*)\n",
        "\n",
        "Aquel enlace debe ser usado en el colab del cliente, disponible en el siguiente link:\n",
        "\n",
        "[Client.ipynb](https://colab.research.google.com/drive/1JXdOO3tzPpzgqm0JFM-V321cc7i5z9AW?usp=sharing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOTUBeeCAlnJ"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=65000, code=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EftDn4WHAm5g",
        "outputId": "fc4775c1-0db5-4457-98ab-e62b79c4e38b"
      },
      "source": [
        "print('Ahora el servidor esta funcionando, puedes ir al achivo de cliente \\ny usar la primera URL acontinuación')\n",
        "server.run_app(app=app)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahora el servidor esta funcionando, puedes ir al achivo de cliente \n",
            "y usar la primera URL acontinuación\n",
            "Public URL: NgrokTunnel: \"https://47c6-104-155-234-23.ngrok.io\" -> \"http://localhost:65000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [66]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:65000 (Press CTRL+C to quit)\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [66]\n"
          ]
        }
      ]
    }
  ]
}